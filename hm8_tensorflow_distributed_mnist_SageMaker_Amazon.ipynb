{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST distributed training  \n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow and MXNet. This tutorial focuses on how to create a convolutional neural network model to train the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using **TensorFlow distributed training**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "('Writing', 'data/train.tfrecords')\n",
      "('Writing', 'data/validation.tfrecords')\n",
      "('Writing', 'data/test.tfrecords')\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-152015771822\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "\n",
    "INPUT_TENSOR_NAME = 'inputs'\n",
    "SIGNATURE_NAME = 'predictions'\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=(mode == Modes.TRAIN))\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    # Define operations\n",
    "    if mode in (Modes.PREDICT, Modes.EVAL):\n",
    "        predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "\n",
    "    if mode in (Modes.TRAIN, Modes.EVAL):\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=tf.one_hot(label_indices, depth=10), logits=logits)\n",
    "        tf.summary.scalar('OptimizeLoss', loss)\n",
    "\n",
    "    if mode == Modes.PREDICT:\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    if mode == Modes.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    if mode == Modes.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Applies the features in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image.set_shape([784])\n",
    "    image = tf.cast(image, tf.float32) * (1. / 255)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, 'train.tfrecords', batch_size=100)\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, 'test.tfrecords', batch_size=100)\n",
    "\n",
    "\n",
    "def _input_fn(training_dir, training_filename, batch_size=100):\n",
    "    test_file = os.path.join(training_dir, training_filename)\n",
    "    filename_queue = tf.train.string_input_producer([test_file])\n",
    "\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "    images, labels = tf.train.batch(\n",
    "        [image, label], batch_size=batch_size,\n",
    "        capacity=1000 + 3 * batch_size)\n",
    "\n",
    "    return {INPUT_TENSOR_NAME: images}, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-152015771822\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:07,564 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:07,564 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:09,117 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,024 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,095 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:{\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:---------------------------------------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:going to training\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.145032: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,145 INFO - root - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,145 INFO - root - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,145 INFO - root - creating the estimator\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using config: {'_model_dir': u's3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints', '_save_checkpoints_secs': 300, '_num_ps_replicas': 2, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': u'worker', '_environment': u'cloud', '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb21f000950>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_num_worker_replicas': 2, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': u'grpc://algo-2:2222', '_log_step_count_steps': 100}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,146 INFO - root - creating Experiment:\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10,146 INFO - root - {'min_eval_frequency': 1000}\u001b[0m\n",
      "\u001b[31mE0309 01:51:10.150216998      61 ev_epoll1_linux.c:1051]     grpc epoll fd: 5\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158036: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> algo-1:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158065: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> algo-1:2223, 1 -> algo-2:2223}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158071: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158830: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158944: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> algo-1:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.158967: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> algo-1:2223, 1 -> localhost:2223}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.159040: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> algo-2:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:10.159412: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2223\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:13,201 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:13,201 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:14,958 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[32m2018-03-09 01:51:16.695914: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session 3aa95dc0823ea5ab with config: gpu_options { per_process_gpu_memory_fraction: 1 } allow_soft_placement: true\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, conv2d/kernel, conv2d/bias, conv2d_1/kernel, conv2d_1/bias, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, beta1_power, beta2_power, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, dense/kernel/Adam, dense/kernel/Adam_1, dense/bias/Adam, dense/bias/Adam_1, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_1/bias/Adam, dense_1/bias/Adam_1, ready: None\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,009 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,181 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:{\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:---------------------------------------------------------\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:going to training\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,230 INFO - root - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,230 INFO - root - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.231174: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,231 INFO - root - creating the estimator\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Using config: {'_model_dir': u's3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints', '_save_checkpoints_secs': 300, '_num_ps_replicas': 2, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': None, '_task_type': u'master', '_environment': u'cloud', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fada2ee7950>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_num_worker_replicas': 2, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': u'grpc://algo-1:2222', '_log_step_count_steps': 100}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,232 INFO - root - creating Experiment:\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16,232 INFO - root - {'min_eval_frequency': 1000}\u001b[0m\n",
      "\u001b[31mE0309 01:51:16.235365633      61 ev_epoll1_linux.c:1051]     grpc epoll fd: 5\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.242641: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> algo-1:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.242670: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2223, 1 -> algo-2:2223}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.242683: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> algo-2:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.243070: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2223\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mMonitors are deprecated. Please use tf.train.SessionRunHook.\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.325673: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.325705: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> algo-1:2223, 1 -> algo-2:2223}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.325711: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> algo-2:2222}\u001b[0m\n",
      "\u001b[31m2018-03-09 01:51:16.325935: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-03-09 01:51:18.221138: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session be1d0b6476d77f61 with config: gpu_options { per_process_gpu_memory_fraction: 1 } allow_soft_placement: true\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1 into s3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 2.2869756, step = 0\u001b[0m\n",
      "\u001b[32m2018-03-09 01:51:46.806274: I tensorflow/core/distributed_runtime/master_session.cc:1004] Start master session ebe0d7e4a4e3ea6d with config: gpu_options { per_process_gpu_memory_fraction: 1 } allow_soft_placement: true\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:loss = 0.2025531, step = 58\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 4.24912\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.033198502, step = 143 (30.194 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.56009\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:loss = 0.033573892, step = 254 (29.474 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.71518\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.031452823, step = 343 (30.490 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.56148\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:loss = 0.0168218, step = 455 (30.690 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.60915\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.050826, step = 545 (30.498 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.63153\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:loss = 0.03687113, step = 652 (29.641 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.56729\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.038492497, step = 747 (30.859 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.56181\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:loss = 0.01802456, step = 849 (29.930 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:global_step/sec: 6.57835\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:loss = 0.009244124, step = 951 (30.587 sec)\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving checkpoints for 1002 into s3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:Loss for final step: 0.053138092.\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:writing success training\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Loss for final step: 0.021236429.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Starting evaluation at 2018-03-09-01:54:18\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints/model.ckpt-1002\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [1/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [2/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [3/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [4/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [5/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [6/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [7/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [8/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [9/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [11/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [12/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [13/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [14/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [15/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [16/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [17/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [18/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [19/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [21/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [22/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [23/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [24/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [25/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [26/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [27/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [28/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [29/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [31/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [32/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [33/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [34/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [35/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [36/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [37/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [38/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [39/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [41/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [42/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [43/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [44/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [45/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [46/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [47/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [48/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [49/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [51/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [52/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [53/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [54/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [55/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [56/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [57/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [58/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [59/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [61/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [62/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [63/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [64/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [65/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [66/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [67/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [68/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [69/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [71/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [72/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [73/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [74/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [75/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [76/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [77/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [78/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [79/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [80/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [81/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [82/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [83/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [84/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [85/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [86/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [87/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [88/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [89/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [90/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [91/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [92/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [93/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [94/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [95/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [96/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [97/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [98/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [99/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Evaluation [100/100]\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Finished evaluation at 2018-03-09-01:54:25\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Saving dict for global step 1002: accuracy = 0.9877, global_step = 1002, loss = 0.037390895\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Restoring parameters from s3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints/model.ckpt-1002\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:SavedModel written to: s3://sagemaker-us-east-1-152015771822/sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437/checkpoints/export/Servo/temp-1520560467/saved_model.pb\u001b[0m\n",
      "\u001b[31mINFO:tensorflow:writing success training\u001b[0m\n",
      "\u001b[31m2018-03-09 01:54:32,798 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-03-09 01:54:32,887 INFO - tf_container.serve - Downloaded saved model at /opt/ml/model/export/Servo/1520560467/saved_model.pb\u001b[0m\n",
      "\u001b[31m2018-03-09 01:54:32,900 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (2): s3.amazonaws.com\u001b[0m\n",
      "\u001b[32mINFO:tensorflow:master algo-1 is down, stopping parameter server\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "mnist_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **```fit```** method will create a training job in two **ml.c4.xlarge** instances. The logs above will show the instances doing training, evaluation, and incrementing the number of **training steps**. \n",
    "\n",
    "In the end of the training, the training job will generate a saved model for TF serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "mnist_predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                             instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "========================================\n",
      "label is 7\n",
      "prediction is 7\n",
      "========================================\n",
      "label is 2\n",
      "prediction is 2\n",
      "========================================\n",
      "label is 1\n",
      "prediction is 1\n",
      "========================================\n",
      "label is 0\n",
      "prediction is 0\n",
      "========================================\n",
      "label is 4\n",
      "prediction is 4\n",
      "========================================\n",
      "label is 1\n",
      "prediction is 1\n",
      "========================================\n",
      "label is 4\n",
      "prediction is 4\n",
      "========================================\n",
      "label is 9\n",
      "prediction is 9\n",
      "========================================\n",
      "label is 5\n",
      "prediction is 5\n",
      "========================================\n",
      "label is 9\n",
      "prediction is 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "for i in range(10):\n",
    "    data = mnist.test.images[i].tolist()\n",
    "    tensor_proto = tf.make_tensor_proto(values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32)\n",
    "    predict_response = mnist_predictor.predict(tensor_proto)\n",
    "    \n",
    "    print(\"========================================\")\n",
    "    label = np.argmax(mnist.test.labels[i])\n",
    "    print(\"label is {}\".format(label))\n",
    "    prediction = predict_response['outputs']['classes']['int64Val'][0]\n",
    "    print(\"prediction is {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-tensorflow-py2-cpu-2018-03-09-01-45-40-437\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(mnist_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
